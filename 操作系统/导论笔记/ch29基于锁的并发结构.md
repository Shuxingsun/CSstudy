# 基于锁的并发数据结构

**关键问题：如何给数据结构加锁**

> 对于特定数据结构，如何加锁才能让该结构功能正确？进一步，如何对该数据结构加锁，能够保证高性能，让许多线程同时访问该结构，即并发访问（concurrently）.



## 并发计数器

简单数据结构：

```c
1 typedef struct counter_t { 
2 int value; 
3 } counter_t; 
4 
5 void init(counter_t *c) { 
6 c->value = 0; 
7 } 
8 
9 void increment(counter_t *c) { 
10 c->value++; 
11 } 
12 
13 void decrement(counter_t *c) { 
14 c->value--; 
15 } 
16 
17 int get(counter_t *c) { 
18 return c->value; 
19 }
```

### 简单但无法扩展

**挑战：**如何让这段代码线程更安全——加锁

```c
1 typedef struct counter_t { 
2 int value; 
3 pthread_mutex_t lock; 
4 } counter_t; 
5 
6 void init(counter_t *c) { 
7 c->value = 0; 
8 Pthread_mutex_init(&c->lock, NULL); 
9 } 
10 
11 void increment(counter_t *c) { 
12 Pthread_mutex_lock(&c->lock); 
13 c->value++; 
14 Pthread_mutex_unlock(&c->lock); 
15 } 
16 
17 void decrement(counter_t *c) { 
18 Pthread_mutex_lock(&c->lock); 
19 c->value--; 
20 Pthread_mutex_unlock(&c->lock); 
21 } 
22 
23 int get(counter_t *c) { 
24 Pthread_mutex_lock(&c->lock); 
25 int rc = c->value; 
26 Pthread_mutex_unlock(&c->lock); 
27 return rc; 
28 }
```

**面临问题：**

- 性能

  - 同步的计数扩展性不好
  - 理想情况，多处理运行的多线程和单线程一样快（**完美扩展**）

  ![](https://picture-house.oss-cn-beijing.aliyuncs.com/notes/2022-04-10_11-05-21.png)



### 可扩展的计数

- **懒惰计数器**：懒惰计数器通过多个局部计数器和一个全局计数器来实现一个逻辑计数器
- **基本思想：**
  - 如果一个核心上的线程想增加计数器，那就**增加它的局部计数器**，访问这个局部计数器是通过对应的局部锁同步的。
  - 因为**每个 CPU 有自己的局部计数器，不同 CPU 上的线程不会竞争**，所以计数器的更新操作可扩展性好
  - 为了保持全局计数器更新（以防某个线程要读取该值），局<u>部值会定期转移给全局计数器，方法是获取全局锁，让全局计数器加上局部计数器的值，然后将局部计数器置零</u>
  - 这种局部转全局的频度，取决于一个阈值，这里称为 *S*（表示 sloppiness）
  - **S 越小，懒惰计数器则越趋近于非扩展的计数器。S 越大，扩展性越强，但是全局计数器与实际计数的偏差越大**。我们可以抢占所有的局部锁和全局锁（以特定的顺序，避免死锁），以获得精确
     值，但这种方法没有扩展性。
  - 如果 S 小，性能很差（但是全局计数器精确度高）。如果 S 大，性能很好，但是全局计数器会有延时。**懒惰计数器就是在准确性和性能之间折中**

| 时间 | L1   | L2   | L3   | L4   | G           |
| ---- | ---- | ---- | ---- | ---- | ----------- |
| 0    | 0    | 0    | 0    | 0    | 0           |
| 1    | 0    | 0    | 1    | 1    | 0           |
| 2    | 1    | 0    | 2    | 1    | 0           |
| 3    | 2    | 0    | 3    | 1    | 0           |
| 4    | 3    | 0    | 3    | 2    | 0           |
| 5    | 4    | 1    | 3    | 3    | 0           |
| 6    | 5->0 | 1    | 3    | 4    | 5(from L1)  |
| 7    | 0    | 2    | 4    | 5->0 | 10(from L4) |

![](https://picture-house.oss-cn-beijing.aliyuncs.com/notes/2022-04-10_11-12-48.png)



## 并发链表

**链表插入：**

```c
1 // basic node structure 
2 typedef struct node_t { 
3 int key; 
4 struct node_t *next; 
5 } node_t; 
6 
7 // basic list structure (one used per list) 
8 typedef struct list_t { 
9 node_t *head; 
10 pthread_mutex_t lock; 
11 } list_t; 
12 
13 void List_Init(list_t *L) { 
14 L->head = NULL;
15 pthread_mutex_init(&L->lock, NULL); 
16 } 
17 
18 int List_Insert(list_t *L, int key) { 
19 pthread_mutex_lock(&L->lock); 
20 node_t *new = malloc(sizeof(node_t)); 
21 if (new == NULL) { 
22 perror("malloc"); 
23 pthread_mutex_unlock(&L->lock); 
24 return -1; // fail 
25 } 
26 new->key = key; 
27 new->next = L->head; 
28 L->head = new; 
29 pthread_mutex_unlock(&L->lock); 
30 return 0; // success 
31 } 
32 
33 int List_Lookup(list_t *L, int key) { 
34 pthread_mutex_lock(&L->lock); 
35 node_t *curr = L->head; 
36 while (curr) { 
37 if (curr->key == key) { 
38 pthread_mutex_unlock(&L->lock); 
39 return 0; // success 
40 } 
41 curr = curr->next; 
42 } 
43 pthread_mutex_unlock(&L->lock); 
44 return -1; // failure 
45 }
```



### 扩展链表

- 增加链表开发计数：**过手锁**（`hand-over-hand locking`，也叫作锁耦合）
- **原理：**<u>每个节点都有一个锁，替代之前整个链表一个锁</u>。遍历链表的时候，首先抢占下一个节点的锁，然后释放当前节点的锁
- 但是实际上，在遍历的时候，每个节点获取锁、释放锁的开销巨大，很难比单锁的方法快

**注意**：如果方案带来了<u>大量的开销（例如，频繁地获取锁、释放锁），那么高并发就没有什么意义</u>



## 并发队列

标准方法创建并发数据结构：**创建一把大锁**

- 两个锁，一个负责队列头，另一个负责队列尾
- 这两个锁使得入队列操作和出队列操作可以并发执行，因为入队列只访问 tail 锁，而出队列只访问 head 锁。

```c
1 typedef struct node_t { 
2 int value; 
3 struct node_t *next; 
4 } node_t; 
5 
6 typedef struct queue_t { 
7 node_t *head; 
8 node_t *tail; 
9 pthread_mutex_t headLock; 
10 pthread_mutex_t tailLock; 
11 } queue_t; 
12 
13 void Queue_Init(queue_t *q) { 
14 node_t *tmp = malloc(sizeof(node_t)); 
15 tmp->next = NULL; 
16 q->head = q->tail = tmp; 
17 pthread_mutex_init(&q->headLock, NULL); 
18 pthread_mutex_init(&q->tailLock, NULL); 
19 } 
20 
21 void Queue_Enqueue(queue_t *q, int value) { 
22 node_t *tmp = malloc(sizeof(node_t));
23 assert(tmp != NULL); 
24 tmp->value = value; 
25 tmp->next = NULL; 
26 
27 pthread_mutex_lock(&q->tailLock); 
28 q->tail->next = tmp; 
29 q->tail = tmp; 
30 pthread_mutex_unlock(&q->tailLock); 
31 } 
32 
33 int Queue_Dequeue(queue_t *q, int *value) { 
34 pthread_mutex_lock(&q->headLock); 
35 node_t *tmp = q->head; 
36 node_t *newHead = tmp->next; 
37 if (newHead == NULL) { 
38 pthread_mutex_unlock(&q->headLock); 
39 return -1; // queue was empty 
40 } 
41 *value = newHead->value; 
42 q->head = newHead; 
43 pthread_mutex_unlock(&q->headLock); 
44 free(tmp); 
45 return 0; 
46 }
```



## 并发散列表

目前只**关注不需要调整大小**的简单散列表

- 每个散列桶（每个桶都是一个链表）都有一个锁，而不是整个散列表只有一个锁，从而支持许多并发操作。

```c
1 #define BUCKETS (101) 
2 
3 typedef struct hash_t { 
4 list_t lists[BUCKETS]; 
5 } hash_t;
6 
7 void Hash_Init(hash_t *H) { 
8 int i; 
9 for (i = 0; i < BUCKETS; i++) { 
10 List_Init(&H->lists[i]); 
11 } 
12 } 
13 
14 int Hash_Insert(hash_t *H, int key) { 
15 int bucket = key % BUCKETS; 
16 return List_Insert(&H->lists[bucket], key); 
17 } 
18 
19 int Hash_Lookup(hash_t *H, int key) { 
20 int bucket = key % BUCKETS; 
21 return List_Lookup(&H->lists[bucket], key); 
22 }
```

![](https://picture-house.oss-cn-beijing.aliyuncs.com/notes/2022-04-10_11-27-47.png)



## 小结：

- 控制流变化时注意获取锁和释放锁；增加并发不一定能提高性能；
-  有性能问题的时候再做优化。
- 关于最后一点，避免不成熟的优化（premature optimization），
  对于所有关心性能的开发者都有用。我们让整个应用的某一小部分变快，却没有提高整体性能，其实没有价值。

